{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJj2vLdPMndg"
   },
   "source": [
    "# Preregistration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9MpoJBjMqeQ"
   },
   "source": [
    "## Study Information\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8GIVRdTMwDP"
   },
   "source": [
    "### Title\n",
    "\n",
    "Benchmarking the Visual Utility of Private Scatterplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5PAR72bOM3HH"
   },
   "source": [
    "### Authors\n",
    "Anonymous for peer review. Online form on [osf.io](https://osf.io/) will list authors upon publication or embargo expiration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_N3sngWMxv-"
   },
   "source": [
    "### Hypotheses\n",
    "\n",
    "\n",
    "1.   Different algorithms' visual utility will vary depending on the shape of the data. This will be determined by the median utility rating being different for at least two of the algorithms as determined by the Friedman test. \n",
    "2.   Different algorithms' visual utility will vary depending on the task associated with the data.  This will be determined by the median utility rating being different for at least two of the algorithms as determined by the Friedman test. \n",
    "3.   Different algorithms' visual utility will vary depending on the privacy level chosen.  This will be determined by the median utility rating being different for at least two of the algorithms as determined by the Friedman test. \n",
    "4.   Different algorithms' visual utility will vary depending on the bin size chosen. This will be determined by the median utility rating being different for at least two of the algorithms as determined by the Friedman test. \n",
    "5.   At least two common metrics of utility will have different strengths of association with the visual utility scores generated. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWVH0m_NjVVp"
   },
   "source": [
    "### Contributions\n",
    "\n",
    "\n",
    "\n",
    "1.   A comparison of differential privacy algorithms' visual utility across a range of tasks, bin sizes, privacy levels, and scatterplot shapes.\n",
    "2.   Guidance on how to display 2D histrograms privately using differential privacy. Discussion on how to improve the visual quality of the output of the data.\n",
    "3.   An examination of how utility metrics correspond to human-percieved utilty.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "634G2JoSNB8Y"
   },
   "source": [
    "## Design Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzsOWfgbNEP3"
   },
   "source": [
    "### Study type \n",
    "\n",
    "Observational Study/Data study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okIvQsdKNIoI"
   },
   "source": [
    "### Blinding \n",
    "\n",
    "Experts will not be able to see either the privacy parameter nor the algorithm used. They will only see the two plots side by side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4vRPISdNL3e"
   },
   "source": [
    "### Study Design\n",
    "The questions are blocked by task. The experts will therefore first go through all questions related to their ability to identify the same correlation in the private plot as the original plot. Then they will proceed through clusters and distribution questions. Inside of these blocks the questions are randomly ordered. Because this is a data study we are not concerned with ordering effects.\n",
    "\n",
    "3 raters will see all the stimuli and give a rating for each one.\n",
    "\n",
    "Five factors:\n",
    "\n",
    "* Algorithm (DAWA, AHP, AGrid, Laplace, Geometric Truncated)\n",
    "* Epsilon, $\\epsilon$ (.5, .1, .05, .01)\n",
    "* Task (Clusters, Distributions, Correlation)\n",
    "* Scatterplot shape (20 different shapes)\n",
    "* Bin Size (32x32, 64x64)\n",
    "\n",
    "Utility Metrics tested:\n",
    "\n",
    "* Average per Query Error - [Paper](https://doi.org/10.48550/arXiv.1512.04817), [Implementation](https://github.com/dpcomp-org/dpcomp_core)\n",
    "* MS-SSIM - [Paper](https://doi.org/10.1109/ACSSC.2003.1292216), [Implementation](https://github.com/VainF/pytorch-msssim)\n",
    "* Scagnostics - [Paper](https://research.tableau.com/sites/default/files/Wilkinson_Infovis-05.pdf), [Implementation](https://pypi.org/project/pyscagnostics/)\n",
    "* Earth Movers Distance - [Paper](https://doi.org/10.1109/TVCG.2017.2745139), [Implementation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wasserstein_distance.html)\n",
    "* 1\\Epsilon - [Paper](https://doi.org/10.48550/arXiv.2201.05964)\n",
    "* SDMetrics - [Paper](https://doi.org/10.48550/arXiv.2112.09238), [Implementation](https://github.com/sdv-dev/SDMetrics)\n",
    "\n",
    "    * KSTest\n",
    "    * BNLikelihood\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmB02J38NSjO"
   },
   "source": [
    "## Sampling Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l03A5uC9NXIX"
   },
   "source": [
    "### Existing data\n",
    "\n",
    "Registration prior to creation of data: As of the date of submission of this research plan for preregistration, the data have not yet been collected, created, or realized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyG9N4O4NX-R"
   },
   "source": [
    "### Data collection procedures\n",
    "\n",
    "Population: Visualization Experts\n",
    "\n",
    "Recruitment efforts: Project collaborators\n",
    "\n",
    "Payment: None\n",
    "\n",
    "Eligibility: Data Visualization Professor\n",
    "\n",
    "Timeline: Data collected in July\n",
    "\n",
    "Data is collected through a study website. There each expert will be able to rate the utility of each plot they see. The data for each expert is exported in a json format indicating the underlying parameters that generated the private plot and the expert rating. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AgkoJvWGNcXe"
   },
   "source": [
    "### Sample size \n",
    "\n",
    "\n",
    "1,200 judgements from three expert reviewers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7J0VnxSNda-"
   },
   "source": [
    "### Sample size rationale\n",
    "\n",
    "Our study is a qualitative data study. We are interested in the way the manipulated variables affected the utility of the data and the not differences of people's perception of utility. Our goal is to test as many parameters as possible and this can be done with a smaller amount of dedicated coders. Previous work done by [Seldmair et al.](https://doi.org/10.1109/TVCG.2013.153) uses two coders when they propose the concept of a qualitative data study. We use three coders since the definition of utility can be hard to pinpoint and having another perspective ensures that our consensus on the private plots utility stems from a broad background. The three coders make 1,200 judgements (5 algorithms x 2 bins sizes x 4 privacy levels x 30 scaterplot/tasks). Not every shape is conducive to all three tasks so each plot was labeled with the tasks an analyst would likely use it for. \n",
    "\n",
    "We did not do the typical user study with many participants and a power analysis for several reasons. Asking participants to answer over a thousand questions requires an unreasonable amount of time and resources. Additionally, participants recruited from a general pool have likely not done extensive data analysis. All three of our experts are experienced in analyzing scatterplot data for the specified tasks. Therefore, they were able to discuss what utility means for a data analyst and come to an agreed upon ranking of utility related to their experience that would have been impossible if a random population sample had been chosen as the study participants. Finally, the majority variation in the ratings stems from the data and not from the reviewers perception of the data.\n",
    "\n",
    "Since we are not comparing across individuals but instead comparing across data variables, we first ran a pilot study to ensure the trained coders agreed upon the evaluation of the data. We use an inter-rater reliability (IRR) metric to ensure the coders consistently agree upon their evaluation of utility. A high IRR ensures that the variation in the utility of the private plots arises from the differences in the plot parameters and not from the differences in coder perception. IRR scores range from a score of 0 to 1. As an example, a score of .8 would mean that 80\\% of the variance is due to the true variance of the underlying data and 20\\% of the variance is due to the differences in coder ratings. A common practice is to set an a-priori value of inter-rater reliability to ensure there is an appropriate amount of agreement amongst the coders before they are presented with the real data. Our a-priori was set at .6 which is classified as substantial aggreement by [Kevin Hallgren](https://doi.org/10.20982%2Ftqmp.08.1.p023). This allows us to attribute the differences in the scores to the data and not to the users. \n",
    "\n",
    "For our pilot study we found an IRR of .7311 with a 95% confidence interval of [0.68, 0.78]. This was an acceptable score based of Kevin Hallgren's recommendations. The statistical analysis can be found in the inter-coder reliability [section](#IRR).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfc8J8B4NgPl"
   },
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCTsgrw9Ni4W"
   },
   "source": [
    "### Manipulated variables\n",
    "\n",
    "We manipulated 5 variables: task type, scatterplot type, privacy level, bin number, algorithm used. \n",
    "\n",
    "There are 3 tasks that we wanted to ensure the user of the private scatterplot could still complete. They are listed below with the wording of the question from the study. \n",
    "\n",
    "\n",
    "*   <b>Distribution: </b>\n",
    "            The distribution of points in space for the graph on the right\n",
    "            is comparable to the graph on the left, including the visibility of \n",
    "            manifolds and the relative density of each region.\n",
    "*   <b>Correlation: </b>\n",
    "            The graph on the right preserves the level of\n",
    "            dependence between the two attributes—including non-linear\n",
    "            dependence.\n",
    "*   <b>Clusters: </b>\n",
    "            The clusters visible in the graph on the left—and\n",
    "            no other clusters—are visible on the graph on the right and occur in\n",
    "            the same places.\n",
    "\n",
    "\n",
    "For our scatterplot types we chose scatterplots from each of the 20 categories generated by [Pandey et al.](https://doi.org/10.1145/2858036.2858155). The scatterplots had points added until all scatterplots had 5000 points. The 20 scatterplots can all be seen in [scatterplotStimuli.pdf](scatterplotStimuli.pdf) and the code to generate them can be found at [scatterplotDensification.ipynb](scatterplotDensification.ipynb). The website that the study was conducted with can be found under [pilotPrivatePlotsStudyWebsite.zip](pilotPrivatePlotsStudyWebsite.zip) with the pilot data added.\n",
    "\n",
    "The privacy level was adjusted by epsilon. The four different levels of epsilon chosen were .5, .1, .05, .01. The two different bin numbers used to generate the binned scatterplots were 32 and 64 evenly-sized bins. The five algorithms selected were [DAWA](https://doi.org/10.48550/arXiv.1410.0265), [AHP](https://doi.org/10.1137/1.9781611973440.68), [AGrid](https://doi.org/10.1109/ICDE.2013.6544872), [Laplace](https://doi.org/10.1007/978-3-540-32732-5_32), and [Geometric Truncated](https://doi.org/10.48550/arXiv.0811.2841). The implementation for DAWA, AHP, and AGrid can be found [here](https://github.com/dpcomp-org/dpcomp_core) and the implementation for Laplace and Geometric Truncated can be found [here](https://diffprivlib.readthedocs.io/en/latest/index.html). The full code to generate the plots can be found at [pilotPrivatePlotGenerationAndStatsErrors.ipynb](pilotPrivatePlotGenerationAndStatsErrors.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQWUuDc9NlUv"
   },
   "source": [
    "### Measured variables\n",
    "\n",
    "The ability of the private plot to retain the task utility is evaluated on a 4 point Likert scale. The categories were limited to four for two reasons. The nuances between different ratings of a more fine grained scale would between difficult to discern and our goal was to keep inter rater reliability high to validate our approach of many datasets tested with a small group of people. Our abbreviated scale can be described as: the user [doesn't, suggests, somewhat, does] retain the ability to complete the task using the private scatterplot when compared to the original binned plot.\n",
    "\n",
    "*   0: Doesn’t preserve the feature\n",
    "*   1: Suggests the feature could exist\n",
    "*   2: Somewhat preserves the feature\n",
    "*   3: Preserves the feature very well\n",
    "\n",
    "To better explain each ratings the reviewers agreed upon the following definitions for each rating:\n",
    "\n",
    "* Doesn’t preserve the feature: I have no confidence that the feature exists.\n",
    "* Suggests the feature could exist: It looks like the feature might exist but I have low confidence and/or the feature is shown with little clarity.\n",
    "* Somewhat preserves the feature: I’m confident this feature exists but its fidelity is meaningfully lower than the original plot.\n",
    "* Preserves the feature very well: I’m confident the feature exists and it is shown with high fidelity relative to the original plot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JKrJ23wNorN"
   },
   "source": [
    "### Indices \n",
    "\n",
    "* <b>Median Utility Rating</b>: To create one rating for each stimulus to use for our analysis from the three ratings that are provided by the coders we use the median of the ratings. Since the data is ordinal and does not have an equal defined spacing between the four ratings we do not use the mean. The median provides us with one homogenous rating from the three raters. \n",
    "\n",
    "* <b>Kendall's $\\tau_b$</b>: For each automated utility metric we will calculate Kendall's $\\tau_b$ for the metric against the median utility rating. This indice will be used to test hypothesis 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5siVoXudNrFH"
   },
   "source": [
    "## Analysis Plan\n",
    "\n",
    "The current analysis code is run with pilot data. Once the study data is collected the exact same code will be run on the full data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HGm_NE7Nt32"
   },
   "source": [
    "### Inter-Rater Reliability\n",
    "\n",
    "<a id='#IRR'></a>\n",
    "\n",
    "To ensure that our task questions and structure were clear across all raters, we ran pilot tests to ensure inter-rater reliability was acceptable. To test the interrater reliability we follow the guidelines for choosing intraclass correlation coefficient (ICC) selection as set out by [Koo and Li](https://doi.org/10.1016%2Fj.jcm.2016.02.012). ICC's are a common way of testing interrater reliatiblity. \n",
    "\n",
    "There are 10 different forms of ICC that rely on different assumptions. To start we are testing for interrater reliability which should not be mistaken for test-retest reliability or intrarater reliability. Interrater reliability measures the variance of across raters on a set of stimuli (stimuli in our case are the private data plots). The selection of the correct ICC comes by defining the model, type, and definition of relationship. Our model is a two-way random effects model. We choose this model because we have the same set of raters evaluate all the data and we generalize our results to any raters who have the same characteristics as our raters. Type asks how the rating will be used in the application. Multiple raters means the average of the ratings will be used while single rater means we will treat the rating as if it came from a single rater though multiple raters made the judgement. Our study involves ordinal data and therefore the average of the three raters does not work. Therefore, we use the single rater type. Finally, for the relationship of the evaluations we can choose between absolute agreement and consistency. For our ratings we are looking for absolute agreement since we want a consensus on utility. \n",
    "\n",
    "Therefore our final ICC selection corresponds to a Two-way mixed effects, absolute agreement, single rater/measurement - ICC(3,1).\n",
    "\n",
    "$\\frac{MS_R-MS_E}{MS_R+(k-1)MS_E}$\n",
    "\n",
    "where $MS_R$ = mean square for rows; $MS_E$ = mean square for error; and k = number of raters/measurements.\n",
    "\n",
    "We used .6 as our minimum cutoff for the kappa to proceed with the actual study. This corresponds with good and substantial agreement from the papers presented by [Cicchetti](https://psycnet.apa.org/doi/10.1037/1040-3590.6.4.284) and [Landis and Koch](https://doi.org/10.2307/2529310)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2h0D2alF0Hw"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install pingouin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "edWwYHGBF45_",
    "outputId": "9696be6f-7f97-4e10-bb7c-7290b57b4d9d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "# assign directory\n",
    "directory = './pilotResults'\n",
    " \n",
    "# iterate over files in\n",
    "# that directory\n",
    "answerDict = {}\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "      # print(f)\n",
    "        file=open(f)\n",
    "        data=json.load(file)\n",
    "        for d in data['answers']:\n",
    "          if d[0] in answerDict:\n",
    "            answerDict[d[0]].append(d[1])\n",
    "          else:\n",
    "            answerDict[d[0]] = [d[1]]\n",
    "\n",
    "answerDataFrame = pd.DataFrame.from_dict(answerDict)\n",
    "answerDataFrame = answerDataFrame.T\n",
    "answerDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mg24VRivF6ev"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "question = answerDataFrame.index.to_numpy()\n",
    "\n",
    "score0 = answerDataFrame[0].to_numpy()\n",
    "score1 = answerDataFrame[1].to_numpy()\n",
    "score2 = answerDataFrame[2].to_numpy()\n",
    "name0 = np.full(len(score0), 0)\n",
    "name1 = np.full(len(score1),1)\n",
    "name2 = np.full(len(score2),2)\n",
    "\n",
    "questions = np.concatenate((question, question, question))\n",
    "raters = np.concatenate((name0, name1, name2))\n",
    "ratings = np.concatenate((score0, score1, score2))\n",
    "\n",
    "df = pd.DataFrame({'question': questions, 'rater': raters, 'ratings': ratings})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "3bqXFWRnF95i",
    "outputId": "5d0930ce-c673-44e0-8b0d-9e303b72d098"
   },
   "outputs": [],
   "source": [
    "import pingouin as pg\n",
    "icc = pg.intraclass_corr(data=df, targets='question', raters='rater',\n",
    "                         ratings='ratings')\n",
    "icc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mGOEt-x7Gjq-"
   },
   "source": [
    "### Algorithm Comparison\n",
    "\n",
    "The selection of best algorithm for all the subsequent analysis follows a three step process:\n",
    "\n",
    "\n",
    "\n",
    "1.   Using the Friedman test, we ensure that there is a difference between the 5 different algorithms. If the Friedman test returns a p value < .05 we continue on step 2 - the post-hoc analysis.\n",
    "2.   We conduct a post-hoc conover test to see which algorithms significantly differ from each other. This gives us more specific insight into which algorithms specifically are different from one another. The post hoc test is corrected for multiple hypothesis testing using the Benjamini/Hochberg method.\n",
    "3.   We visualize the data to examine the results from the post-hoc conover test to see which of the algorithms that have statistically significant differences in their results yield higher visual utility.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated Utility Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhtaK3snrCLr"
   },
   "source": [
    "We want to measure the strength of association between the visual utility ratings generated by our coders and metrics of utility that can be generated computationaly. Our coder rankings are ordinal and the metrics are continuous. When obtaining the association of ordinal-continuous variables [Harry Khamis](https://doi.org/10.1177/8756479308317006) recommends using Kendall's coeficient of rank correlation $τ_b$. $τ_b$ can range from -1 (perfect negative association) to 1 (perfect positive assocation). \n",
    "\n",
    "\n",
    "We calculate every metric (Average per query error, MS-SSIM, Scagnostics, 1/epsilon, Earth Movers Distance, KSTest, BNLikelihood) on every stimulus comparing the binned non private with the binned private plot. We match these plots based on all the parameters (algorithm, task, bin size, shape, epsilon). For each metric we find Kendall's $\\tau_b$. We use the [implementation](https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.stats.kendalltau.html) provided by scipy.stats.\n",
    "\n",
    "\n",
    "We are submitting the preregistration without the implementation for all the metrics in our code. Links to the respective libraries we plan to use are provided.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Criteria\n",
    "\n",
    "To test our hypotheses we will be using a holistic approach. We will look at both the p-value the Friedman test returns as well as examining the distributions found in the data to see if there is a meaningful difference between the algorithms. We will also this approach for the post-hoc analysis.\n",
    "\n",
    "While we have no specific hypothesis for the statistical utility correlations with visual utility, we will determine which metric is best used by finding the one with the highest positive correlation that has a p-value of less than .05. To test hypothesis 5, we will use the fisher z-transformation to test the different metrics corrrelation coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P-Value Interpretation\n",
    "\n",
    "This p-value is the conditional probability of the data (or any result even more extreme) assuming:\n",
    "\n",
    "1. the null hypothesis H0 is exactly true,\n",
    "2. the study is repeated an infinite number times by drawing random samples from the same populations(s),\n",
    "3. all distributional requirements are met, and\n",
    "4. there is no source of error besides sampling or measurement error.\n",
    "\n",
    "p-value interpretation based on ([Kline, 2013](https://doi.org/10.1037/14136-000)])."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY8Fv_N1lSvS"
   },
   "source": [
    "#### Code for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cDJbS032j-ZJ"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import statistics\n",
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "\n",
    "!pip install scikit-posthocs\n",
    "import scikit_posthocs as sp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aIdQ2hhMIqJu"
   },
   "outputs": [],
   "source": [
    "\n",
    "medianArray = []\n",
    "for index, row in answerDataFrame.iterrows():\n",
    "    medianArray.append( statistics.median([row[0], row[1], row[2]]))\n",
    "\n",
    "answerDataFrame['totalRating'] = medianArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "heLs_KKdRNNW"
   },
   "outputs": [],
   "source": [
    "tasks = ['distribution', 'clusters', 'correlation']\n",
    "epsilons = ['0.5', '0.1', '0.05', '0.01']\n",
    "algorithms = ['DAWA', 'AHP', \"AGrid\", 'Geometric', 'Laplace']\n",
    "bins = ['32','64']\n",
    "chart = ['0','2','3','9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Uq4GegheUnH"
   },
   "outputs": [],
   "source": [
    "def getFilteredArray(df, name):\n",
    "  dataFiltered = df.filter(like=name, axis=0)\n",
    "  DAWA = []\n",
    "  AHP = []\n",
    "  AGrid = []\n",
    "  Geometric = []\n",
    "  Laplace = []\n",
    "  exDF = dataFiltered\n",
    "  while len(exDF.index)>0:\n",
    "    count = 0\n",
    "    for e in epsilons:\n",
    "      for b in bins:\n",
    "        for t in tasks:\n",
    "          for c in chart:            \n",
    "            for index, row in exDF.iterrows():\n",
    "              if count !=5:\n",
    "                \n",
    "                if c+'_' in index and b in index and t in index and e in index:\n",
    "\n",
    "\n",
    "                  if 'Laplace' in index:\n",
    "                      \n",
    "                      Laplace.append(row['totalRating'])\n",
    "                      exDF = exDF.drop(index)\n",
    "                      count = count+1\n",
    "                  if 'AHP' in index:\n",
    "                    \n",
    "\n",
    "                    AHP.append(row['totalRating'])\n",
    "                    exDF = exDF.drop(index)\n",
    "                    count = count+1\n",
    "                  if 'AGrid' in index:\n",
    "                    \n",
    "\n",
    "                    AGrid.append(row['totalRating'])\n",
    "                    exDF = exDF.drop(index) \n",
    "                    count = count+1\n",
    "                  if 'Geometric' in index:\n",
    "                    \n",
    "\n",
    "                    Geometric.append(row['totalRating'])\n",
    "                    exDF = exDF.drop(index) \n",
    "                    count = count+1\n",
    "                  if 'DAWA' in index:\n",
    "                  \n",
    "\n",
    "                    DAWA.append(row['totalRating'])\n",
    "                    exDF = exDF.drop(index) \n",
    "                    count = count+1\n",
    "    \n",
    "  dfAlgorithms =  pd.DataFrame({'DAWA': DAWA, 'AHP': AHP, 'AGrid': AGrid, 'Geometric': Geometric, 'Laplace': Laplace})\n",
    "  return dfAlgorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CY2lQvHzlDyQ"
   },
   "source": [
    "##### Step 1: Friedman Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yNv3RBq0erYp"
   },
   "outputs": [],
   "source": [
    "def getFriedmanResult(df):\n",
    "  stat, p = friedmanchisquare(df['DAWA'], df['AHP'],df['AGrid'], df['Geometric'], df['Laplace'])\n",
    "  print('Statistics=%.3f, p=%.3f' % (stat, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWM7a5uWlHFY"
   },
   "source": [
    "##### Step 2: Post Hoc Conover\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZDocnOxXe0en"
   },
   "outputs": [],
   "source": [
    "def getConoverPostHoc(df):\n",
    "  newLook = sp.__convert_to_block_df(df)\n",
    "  pc = sp.posthoc_conover(newLook[0], val_col='y', group_col='groups', p_adjust = 'fdr_bh')\n",
    "  pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "  return pc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ykz2jcDlKlZ"
   },
   "source": [
    "##### Step 3: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x1a00Mmwe-mv"
   },
   "outputs": [],
   "source": [
    "def getVisual(df):\n",
    "  frequencies = {}\n",
    "  for i in df.columns:\n",
    "      frequencies[i] = df[i].value_counts()\n",
    "  plotdata = pd.DataFrame(frequencies)\n",
    "  plotdata = plotdata.transpose()\n",
    "  plotdata2 = plotdata.div(plotdata.sum(axis=1), axis=0)*100\n",
    "  plotdata2.plot(kind=\"barh\", stacked=True)\n",
    "  plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "  plt.ylabel('Algorithm')\n",
    "  plt.xlabel('Cumulative Percent')\n",
    "  # return plotdata2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFCzFvTgY9nj"
   },
   "source": [
    "#### Best Overall Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VrPup6PtkRSJ"
   },
   "outputs": [],
   "source": [
    "filteredDf = getFilteredArray(answerDataFrame, '0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uk57a3Bskb6y",
    "outputId": "1665353f-2c51-49e1-a64a-4efa4fe175dc"
   },
   "outputs": [],
   "source": [
    "getFriedmanResult(filteredDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "tcLoe003keqO",
    "outputId": "9917974e-9f2a-4376-c29c-a1a6c5d1d37d"
   },
   "outputs": [],
   "source": [
    "getConoverPostHoc(filteredDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "lSfG4tpTkgyZ",
    "outputId": "ae8fc9a1-8e90-4f91-d1d9-688bf7afda46"
   },
   "outputs": [],
   "source": [
    "getVisual(filteredDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hsRc5rJJGmcW"
   },
   "source": [
    "#### Different Privacy Levels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1COY3knYbJq5"
   },
   "source": [
    "##### Epsilon = .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UTDGrD7bfOex"
   },
   "outputs": [],
   "source": [
    "filteredDf = getFilteredArray(answerDataFrame, '_0.5_')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9squYfUff9o-",
    "outputId": "589b3c39-fd25-4268-bf65-0290d5e7458a"
   },
   "outputs": [],
   "source": [
    "getFriedmanResult(filteredDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "TqaQISS3gT-G",
    "outputId": "7dafd5c0-1cf0-423c-e347-30572b2f603b"
   },
   "outputs": [],
   "source": [
    "getConoverPostHoc(filteredDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "Zvo7GUzTgYc9",
    "outputId": "4a11c949-5981-431a-c9fa-19bf98d4b7ad"
   },
   "outputs": [],
   "source": [
    "getVisual(filteredDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYAHfIcugy7X"
   },
   "source": [
    "##### Epsilon .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "75poyMBPg2as"
   },
   "outputs": [],
   "source": [
    "filteredDf = getFilteredArray(answerDataFrame, '_0.1_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gcO6lbMHg6Gs",
    "outputId": "f52505ff-160e-4598-890d-6833167ad470"
   },
   "outputs": [],
   "source": [
    "getFriedmanResult(filteredDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "CCGONrf-g8BM",
    "outputId": "f3c8a157-5dd1-47aa-b6ff-068b5a6bb80c"
   },
   "outputs": [],
   "source": [
    "getConoverPostHoc(filteredDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "whp4CYtvg9GV",
    "outputId": "16cf02e8-3f5b-446a-8a11-83068810f606"
   },
   "outputs": [],
   "source": [
    "getVisual(filteredDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvXZbvWKg9sF"
   },
   "source": [
    "##### Epsilon .05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EhAzxPqohF_t"
   },
   "outputs": [],
   "source": [
    "filteredDf = getFilteredArray(answerDataFrame, '_0.05_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XsPyJmtZhG-V",
    "outputId": "cc6deaf5-3f82-4f2c-e111-d0e17116147b"
   },
   "outputs": [],
   "source": [
    "getFriedmanResult(filteredDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "D14lUo17hHEc",
    "outputId": "cb4ae057-c350-4518-8cdf-784a148e1f1d"
   },
   "outputs": [],
   "source": [
    "getConoverPostHoc(filteredDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "QHGdzI2qhHHM",
    "outputId": "dfb34abb-e300-49a4-d4e3-e204981f809a"
   },
   "outputs": [],
   "source": [
    "getVisual(filteredDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgSfpqHhhLEO"
   },
   "source": [
    "##### Epsilon .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aSXa3oQ4hNeE"
   },
   "outputs": [],
   "source": [
    "filteredDf = getFilteredArray(answerDataFrame, '_0.01_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r9-WcU7AhOWc",
    "outputId": "2acc218f-0ea3-4d96-836a-9e874048833a"
   },
   "outputs": [],
   "source": [
    "getFriedmanResult(filteredDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "1atm8mdWhOY7",
    "outputId": "28379ac2-8f1e-49dd-c75f-49a85b118ddc"
   },
   "outputs": [],
   "source": [
    "getConoverPostHoc(filteredDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "MgDwvxxnhObO",
    "outputId": "152d5fe4-e042-4109-9c66-f2e0a8088d5e"
   },
   "outputs": [],
   "source": [
    "getVisual(filteredDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ik23MDyMlcvQ"
   },
   "source": [
    "#### Different Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_02c-stlsPo"
   },
   "source": [
    "##### Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yeMFtsl4ljug"
   },
   "outputs": [],
   "source": [
    "filteredDf = getFilteredArray(answerDataFrame, 'distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5HJcGI6dlwMY",
    "outputId": "eb5d2f6b-dd75-41ca-d9f4-d31823e0fc98"
   },
   "outputs": [],
   "source": [
    "getFriedmanResult(filteredDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "v4MlqIU7lxsY",
    "outputId": "37c8ddda-a597-4525-8c14-f3cbebefff18"
   },
   "outputs": [],
   "source": [
    "getConoverPostHoc(filteredDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "baGIMWr-lzDI",
    "outputId": "41243577-a384-4a26-f254-d6875f655be6"
   },
   "outputs": [],
   "source": [
    "getVisual(filteredDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bhnn_LCBlzXL"
   },
   "source": [
    "##### Correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IXQCsTkLl2iQ"
   },
   "outputs": [],
   "source": [
    "filteredDf = getFilteredArray(answerDataFrame, 'correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BxapZiRzl2kQ",
    "outputId": "328102a1-c86e-4d1a-80ce-721b7330045a"
   },
   "outputs": [],
   "source": [
    "getFriedmanResult(filteredDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "tqQ1B4Ucl2mg",
    "outputId": "9efebc9b-0f13-4b82-e849-7a7403389e00"
   },
   "outputs": [],
   "source": [
    "getConoverPostHoc(filteredDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "0ovVN0yFl2op",
    "outputId": "01e2db0e-6df9-4dc0-bec0-35af603fce71"
   },
   "outputs": [],
   "source": [
    "getVisual(filteredDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t31r0K1nl6VR"
   },
   "source": [
    "##### Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utIyfwS7l73A"
   },
   "outputs": [],
   "source": [
    "filteredDf = getFilteredArray(answerDataFrame, 'clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9GpjIu2el75Q",
    "outputId": "448044ce-685b-427d-c620-fbe642d50a18"
   },
   "outputs": [],
   "source": [
    "getFriedmanResult(filteredDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "RUUxu7Fhl77g",
    "outputId": "93cf6171-1ada-433b-cf54-11ddaadecefc"
   },
   "outputs": [],
   "source": [
    "getConoverPostHoc(filteredDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "PGFWKkDCl79Q",
    "outputId": "b13690c3-5872-45d2-933b-aeb14f876d06"
   },
   "outputs": [],
   "source": [
    "getVisual(filteredDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_3admOanIR_"
   },
   "source": [
    "#### Different Bin Sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7uw6rgz8nK1P"
   },
   "source": [
    "##### 32 Bins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lc33TiNlnOig"
   },
   "outputs": [],
   "source": [
    "filteredDf = getFilteredArray(answerDataFrame, '32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wBTRL1sZnOkm",
    "outputId": "70043516-f71e-4ea7-cf83-437cb96d34b8"
   },
   "outputs": [],
   "source": [
    "getFriedmanResult(filteredDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "mksRs5rQnOmv",
    "outputId": "26f7cb73-df9b-47f8-ae55-dd8f2764d268"
   },
   "outputs": [],
   "source": [
    "getConoverPostHoc(filteredDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "urKSipNVnO4o",
    "outputId": "9ae743e0-2dd8-45d0-b13c-0076cb3bafea"
   },
   "outputs": [],
   "source": [
    "getVisual(filteredDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4n4Z6pl6nUD3"
   },
   "source": [
    "##### 64 Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wGfYRY4tnY8v"
   },
   "outputs": [],
   "source": [
    "filteredDf = getFilteredArray(answerDataFrame, '64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VthKZzL4nY_X",
    "outputId": "031f0171-235c-42ad-854b-54dbf703648b"
   },
   "outputs": [],
   "source": [
    "getFriedmanResult(filteredDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Nk_OazWxnZBn",
    "outputId": "9495b936-8e8f-4f07-f0ce-928449c98840"
   },
   "outputs": [],
   "source": [
    "getConoverPostHoc(filteredDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "plGSLVFVnZEI",
    "outputId": "6178bd25-85f2-4c0d-cdb8-a41b4b008cdc"
   },
   "outputs": [],
   "source": [
    "getVisual(filteredDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLht7SM9oWMe"
   },
   "source": [
    "#### Statistical Metrics vs Visual Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zwecDN_bodg1"
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWQW85sr-gns"
   },
   "source": [
    "The code for generating the pilot plots and utility metrics csv can be found at [pilotPrivatePlotGenerationAndStatsErrors.ipynb](pilotPrivatePlotGenerationAndStatsErrors.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZz2_zZ0NMZT"
   },
   "outputs": [],
   "source": [
    "dfMetrics = pd.read_csv('./statisticalUtilityMetrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "jfcNLnI40xsb",
    "outputId": "86dc591a-fb49-42ba-ebc7-baccefed7953"
   },
   "outputs": [],
   "source": [
    "from re import M\n",
    "import numpy as np\n",
    "len(answerDataFrame['totalRating'])\n",
    "\n",
    "metrics = ['Random Query', 'MSSIM']\n",
    "\n",
    "associationDf = pd.DataFrame(columns = ['tau', 'pValue'])\n",
    "for m in metrics:\n",
    "  tau, p_value = stats.kendalltau(dfMetrics['totalRating'], dfMetrics[m])\n",
    "  row = pd.Series({'tau':tau,'pValue':p_value},name= m)\n",
    "  associationDf = associationDf.append(row)\n",
    "\n",
    "associationDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Coefficient Comparison\n",
    "\n",
    "We use Fisher’s z-transformation to test all the different correlations for any difference. If the p-value is less than .05 for at least one of the comparisons we accept hypothesis 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code copied from https://github.com/psinger/CorrelationStats/blob/master/corrstats.py\n",
    "\n",
    "from scipy.stats import t, norm\n",
    "from math import atanh, pow\n",
    "from numpy import tanh\n",
    "\n",
    "def independent_corr(xy, ab, n, n2 = None, twotailed=True, conf_level=0.95, method='fisher'):\n",
    "    \"\"\"\n",
    "    Calculates the statistic significance between two independent correlation coefficients\n",
    "    @param xy: correlation coefficient between x and y\n",
    "    @param xz: correlation coefficient between a and b\n",
    "    @param n: number of elements in xy\n",
    "    @param n2: number of elements in ab (if distinct from n)\n",
    "    @param twotailed: whether to calculate a one or two tailed test, only works for 'fisher' method\n",
    "    @param conf_level: confidence level, only works for 'zou' method\n",
    "    @param method: defines the method uses, 'fisher' or 'zou'\n",
    "    @return: z and p-val\n",
    "    \"\"\"\n",
    "\n",
    "    if method == 'fisher':\n",
    "        xy_z = 0.5 * np.log((1 + xy)/(1 - xy))\n",
    "        ab_z = 0.5 * np.log((1 + ab)/(1 - ab))\n",
    "        if n2 is None:\n",
    "            n2 = n\n",
    "\n",
    "        se_diff_r = np.sqrt(1/(n - 3) + 1/(n2 - 3))\n",
    "        diff = xy_z - ab_z\n",
    "        z = abs(diff / se_diff_r)\n",
    "        p = (1 - norm.cdf(z))\n",
    "        if twotailed:\n",
    "            p *= 2\n",
    "\n",
    "        return z, p\n",
    "    elif method == 'zou':\n",
    "        L1 = rz_ci(xy, n, conf_level=conf_level)[0]\n",
    "        U1 = rz_ci(xy, n, conf_level=conf_level)[1]\n",
    "        L2 = rz_ci(ab, n2, conf_level=conf_level)[0]\n",
    "        U2 = rz_ci(ab, n2, conf_level=conf_level)[1]\n",
    "        lower = xy - ab - pow((pow((xy - L1), 2) + pow((U2 - ab), 2)), 0.5)\n",
    "        upper = xy - ab + pow((pow((U1 - xy), 2) + pow((ab - L2), 2)), 0.5)\n",
    "        return lower, upper\n",
    "    else:\n",
    "        raise Exception('Wrong method!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_corr(associationDf['tau'][0], associationDf['tau'][1], 1200, 1200)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Preregistration.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
