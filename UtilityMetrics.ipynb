{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzmLc2oQeE9S"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!git clone https://github.com/dpcomp-org/dpcomp_core.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0JdPf2ZeOF2"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install diffprivlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxDFsWZOeRfg"
      },
      "outputs": [],
      "source": [
        "# Remove default module\n",
        "%%capture\n",
        "%cd dpcomp_core\n",
        "!rm -r dpcomp_core"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wymdRqVTeTVr"
      },
      "outputs": [],
      "source": [
        "# Get zipped new module from Jane's server\n",
        "%%capture\n",
        "!wget https://dev.universalities.com/dpcomp_core.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUSj2U5IeUml"
      },
      "outputs": [],
      "source": [
        "# Unzip Jane's version of the module\n",
        "%%capture\n",
        "!unzip dpcomp_core.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtayFlIeeWT4"
      },
      "outputs": [],
      "source": [
        "# Add requirements so pip does the version matching right\n",
        "!echo diffprivlib >> resources/requirements.txt\n",
        "!echo pandas >> resources/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9V1BetaLeXio"
      },
      "outputs": [],
      "source": [
        "# Install pip requirements\n",
        "%%capture\n",
        "!pip install -r resources/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7pVuR9AeZDt"
      },
      "outputs": [],
      "source": [
        "# Install swig\n",
        "%%capture\n",
        "!apt-get install swig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fxUFIDBeaNE"
      },
      "outputs": [],
      "source": [
        "# Run C++ setup for DAWA\n",
        "%%capture\n",
        "%cd dpcomp_core/algorithm/dawa/\n",
        "!bash setup.sh\n",
        "%cd ../../../"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "u8YrGas2ebg_",
        "outputId": "61d760d0-712c-4d50-f568-0e23af902ad5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/dpcomp_core'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7ug1qMHg4S-",
        "outputId": "ed49f52f-4dd7-4cba-b80d-ad45103b5c59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/dpcomp_core/dpcomp_core/algorithm/ahp\n",
            "rm: cannot remove 'ahp_fast.c': No such file or directory\n",
            "rm: cannot remove '*.so': No such file or directory\n",
            "Compiling lib/ahp_fast.pyx because it changed.\n",
            "[1/1] Cythonizing lib/ahp_fast.pyx\n",
            "/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:367: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/dpcomp_core/dpcomp_core/algorithm/ahp/lib/ahp_fast.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "running build_ext\n",
            "building 'ahp_fast' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/lib\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.7m -c lib/ahp_fast.c -o build/temp.linux-x86_64-3.7/lib/ahp_fast.o\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/lib/ahp_fast.o -o /content/dpcomp_core/dpcomp_core/algorithm/ahp/ahp_fast.cpython-37m-x86_64-linux-gnu.so\n",
            "/content/dpcomp_core\n"
          ]
        }
      ],
      "source": [
        "%cd dpcomp_core/algorithm/ahp/\n",
        "!bash setup.sh\n",
        "%cd ../../../"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LY3IVtKae6ST"
      },
      "outputs": [],
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from past.utils import old_div\n",
        "from dpcomp_core.algorithm import dawa\n",
        "from dpcomp_core.algorithm import AG\n",
        "from dpcomp_core.algorithm import ahp\n",
        "from dpcomp_core import dataset\n",
        "from dpcomp_core import workload\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWwfRdu9g6uc"
      },
      "outputs": [],
      "source": [
        "def runDAWA(data, bin, epsilon):\n",
        "  domain = (bin,bin)\n",
        "  epsilon = epsilon\n",
        "\n",
        "\n",
        "  seed = 1\n",
        "  shape_list = [(5,5),(10,10)]\n",
        "  size = 5000\n",
        "\n",
        "  w = workload.RandomRange(shape_list=shape_list, \n",
        "                         domain_shape=domain, \n",
        "                         size=size, \n",
        "                         seed=seed)\n",
        "\n",
        "  a = dawa.dawa2D_engine()\n",
        "  H, xedges, yedges = np.histogram2d(data['x'], data['y'], bins = bin)\n",
        "  H = H.T\n",
        "  x_hat = a.Run(w, H, epsilon, seed)\n",
        "  return x_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvO2uH2gqbVK"
      },
      "outputs": [],
      "source": [
        "def runAHP(data, bin, epsilon):\n",
        "  domain = (bin,bin)\n",
        "\n",
        "  seed = 1\n",
        "  shape_list = [(5,5),(10,10)]\n",
        "  size = 5000\n",
        "\n",
        "  w = workload.RandomRange(shape_list=shape_list, \n",
        "                        domain_shape=domain, \n",
        "                        size=size, \n",
        "                        seed=seed)\n",
        "\n",
        "  a = ahp.ahpND_engine(ratio = 0.85, eta = 0.35)\n",
        "  H, xedges, yedges = np.histogram2d(data['x'], data['y'], bins = bin)\n",
        "  H = H.T\n",
        "  x_hat = a.Run(w, H, epsilon, seed)\n",
        "  return x_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuj4DkrXrCBo"
      },
      "outputs": [],
      "source": [
        "def runAGrid(data, bin, epsilon):\n",
        "  domain = (bin,bin)\n",
        "  seed = 1\n",
        "  shape_list = [(5,5),(10,10)]\n",
        "  size = 5000\n",
        "\n",
        "  w = workload.RandomRange(shape_list=shape_list, \n",
        "                        domain_shape=domain, \n",
        "                        size=size, \n",
        "                        seed=seed)\n",
        "\n",
        "  a = AG.AG_engine(c = 10, c2 = 5, alpha = 0.5)\n",
        "  H, xedges, yedges = np.histogram2d(data['x'], data['y'], bins = bin)\n",
        "  H = H.T\n",
        "  x_hat = a.Run(w, H, epsilon, seed)\n",
        "  return x_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAjFlmrdr5hH"
      },
      "outputs": [],
      "source": [
        "from diffprivlib.tools import histogram2d\n",
        "def runGeoTruncated(data, bin, epsilon):\n",
        "  newList = histogram2d(data['x'],data['y'],epsilon,bin, density = False)\n",
        "  x_hat = newList[0].T\n",
        "  return x_hat\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWwcOapqz2EX"
      },
      "outputs": [],
      "source": [
        "from diffprivlib.mechanisms.laplace import Laplace\n",
        "\n",
        "from sys import maxsize\n",
        "def histogramdd(sample, epsilon, bins, range=None, weights=None, density=None, accountant=None, **unused_args):\n",
        "\n",
        "    hist, bin_edges = np.histogramdd(sample, bins=bins, range=range, normed=None, weights=weights, density=None)\n",
        "\n",
        "    dp_mech = Laplace().set_epsilon(epsilon).set_sensitivity(1)\n",
        "    dp_hist = np.zeros_like(hist)\n",
        "    iterator = np.nditer(hist, flags=['multi_index'])\n",
        "\n",
        "    while not iterator.finished:\n",
        "        dp_hist[iterator.multi_index] = dp_mech.randomise(int(iterator[0]))\n",
        "        iterator.iternext()\n",
        "\n",
        "    dp_hist = dp_hist.astype(float, casting='safe')\n",
        "\n",
        "    if density:\n",
        "        # calculate the probability density function\n",
        "        dims = len(dp_hist.shape)\n",
        "        dp_hist_sum = dp_hist.sum()\n",
        "        for i in np.arange(dims):\n",
        "            shape = np.ones(dims, int)\n",
        "            shape[i] = dp_hist.shape[i]\n",
        "            # noinspection PyUnresolvedReferences\n",
        "            dp_hist = dp_hist / np.diff(bin_edges[i]).reshape(shape)\n",
        "\n",
        "        if dp_hist_sum > 0:\n",
        "            dp_hist /= dp_hist_sum\n",
        "\n",
        "  \n",
        "\n",
        "    return dp_hist, bin_edges\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Oczq5JC0LWe"
      },
      "outputs": [],
      "source": [
        "def laplaceHistogram(array_x, array_y, epsilon, bins, range=None, weights=None, density=None, accountant=None,\n",
        "                **unused_args):\n",
        "\n",
        "    try:\n",
        "        num_bins = len(bins)\n",
        "    except TypeError:\n",
        "        num_bins = 1\n",
        "\n",
        "    if num_bins not in (1, 2):\n",
        "        xedges = yedges = np.asarray(bins)\n",
        "        bins = [xedges, yedges]\n",
        "\n",
        "    hist, edges = histogramdd([array_x, array_y], epsilon=epsilon, bins=bins, range=range, weights=weights,\n",
        "                              density=density, accountant=accountant)\n",
        "    \n",
        "    return hist, edges[0], edges[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yzVZqX9yJpR"
      },
      "outputs": [],
      "source": [
        "def runLaplace(data, bin, epsilon):\n",
        "  newList = laplaceHistogram(data['x'],data['y'],epsilon,bin, density = False)\n",
        "  x_hat = newList[0].T\n",
        "  return x_hat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu-aZTSxsErp",
        "outputId": "e05b3903-e01c-48dd-e02b-3c5c7f017d34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dpcomp_core.query_nd_union.ndRangeUnion"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seed = 1\n",
        "domain = (32,32)\n",
        "shape_list = [(5,5),(10,10)]\n",
        "size = 5000\n",
        "\n",
        "w = workload.RandomRange(shape_list=shape_list, \n",
        "                        domain_shape=domain, \n",
        "                        size=size, \n",
        "                        seed=seed)\n",
        "type(w.query_list[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_T4N5fPGplEF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGqjM0nbdGd6"
      },
      "outputs": [],
      "source": [
        "tasks = ['distribution', 'clusters', 'correlation']\n",
        "epsilons = [.5, .1, .05, .01]\n",
        "algorithms = ['DAWA', 'AHP', \"AGrid\", 'Geometric', 'Laplace']\n",
        "bins = [32,64]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wx45469yc6rk"
      },
      "outputs": [],
      "source": [
        "chartDictionary = {'0': ['distribution', 'correlation'], '1': ['distribution'], \n",
        "                   '2': ['distribution', 'clusters', 'correlation'], '3': ['distribution'],\n",
        "                   '4': ['distribution', 'clusters'], '5': [ 'correlation'],\n",
        "                   '6': ['distribution', 'correlation'], '7': ['distribution', 'correlation'],\n",
        "                   '8':['distribution'], '9': ['distribution'],\n",
        "                   '10': ['distribution', 'clusters'], '11': ['distribution', 'correlation'],\n",
        "                   '12': ['correlation'], '13': ['distribution', 'correlation'],\n",
        "                   '14': ['correlation'], '15': ['distribution'],\n",
        "                   '16': ['distribution', 'clusters'], '17': ['distribution'],\n",
        "                   '18': ['clusters'], '19': ['distribution']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgAUu5f1deuc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcHri7n12tuv"
      },
      "outputs": [],
      "source": [
        "def getL2(H, x_hat, bins):\n",
        "  seed = 1\n",
        "  domain = (bins,bins)\n",
        "  shape_list = [(5,5),(10,10)]\n",
        "  size = 5000\n",
        "\n",
        "  w = workload.RandomRange(shape_list=shape_list, \n",
        "                         domain_shape=domain, \n",
        "                         size=size, \n",
        "                         seed=seed)\n",
        "\n",
        "\n",
        "  diff = w.evaluate(H) - w.evaluate(x_hat)\n",
        "  # print('Per Query Average Absolute Error:', old_div(np.linalg.norm(diff,1), float(diff.size)))\n",
        "  return(old_div(np.linalg.norm(diff,1), float(diff.size)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "708d1gEgC-ub",
        "outputId": "e25fae60-e680-4c80-c30e-56f27e947338"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-msssim\n",
            "  Downloading pytorch_msssim-0.2.1-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pytorch-msssim) (1.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-msssim) (4.1.1)\n",
            "Installing collected packages: pytorch-msssim\n",
            "Successfully installed pytorch-msssim-0.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-msssim\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import matplotlib.colors as colors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkIqDYXbZ0sT",
        "outputId": "281cdddb-2f26-42b4-cecf-deaa61b02dd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ySakzaq_gmh"
      },
      "outputs": [],
      "source": [
        "def getMSSIM(H, x_hat):\n",
        "  plt.imshow(H, interpolation='nearest', origin='lower', cmap = 'gray_r', aspect = 'auto',\n",
        "        extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]])\n",
        "  ax = plt.gca()\n",
        "\n",
        "  ax.axes.xaxis.set_ticklabels([])\n",
        "  ax.axes.yaxis.set_ticklabels([])\n",
        "  plt.savefig('H.png')\n",
        "  \n",
        "\n",
        "  plt.imshow(x_hat, interpolation='nearest', origin='lower', cmap = 'gray_r', aspect = 'auto',\n",
        "        extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]])\n",
        "  ax = plt.gca()\n",
        "\n",
        "  ax.axes.xaxis.set_ticklabels([])\n",
        "  ax.axes.yaxis.set_ticklabels([])\n",
        "  plt.savefig('x_hat.png')\n",
        "\n",
        "  img = Image.open('H.png')\n",
        "  X = np.array(img).astype(np.float32)\n",
        "\n",
        "  img = Image.open('x_hat.png')\n",
        "  Y = np.array(img).astype(np.float32)\n",
        "  img_torch = torch.from_numpy(X).unsqueeze(0).permute(0, 3, 1, 2)  # 1, C, H, W\n",
        "  img_noise_torch = torch.from_numpy(Y).unsqueeze(0).permute(0, 3, 1, 2)\n",
        "  # print(img_noise_torch)\n",
        "  msssim_torch = ms_ssim(img_torch, img_noise_torch, win_size=11, data_range=255)\n",
        "\n",
        "  val = msssim_torch.item()\n",
        "  os.remove('H.png')\n",
        "  os.remove('x_hat.png')\n",
        "\n",
        "  return val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yo_7IlW4P2-0"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import wasserstein_distance\n",
        "def getEarthMoversDistance(H, x_hat):\n",
        "  H = H.flatten()\n",
        "  x_hat = x_hat.flatten()\n",
        "  return wasserstein_distance(H, x_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l6vYx8zcw5CG",
        "outputId": "0126f242-1cfa-49fb-a98e-590d02c5d87c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sdmetrics\n",
            "  Downloading sdmetrics-0.5.0-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from sdmetrics) (1.12.0+cu113)\n",
            "Collecting copulas<0.8,>=0.7.0\n",
            "  Downloading copulas-0.7.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting scipy<2,>=1.5.4\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 67.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn<2,>=0.24 in /usr/local/lib/python3.7/dist-packages (from sdmetrics) (1.0.2)\n",
            "Collecting pyts<0.13.0,>=0.12.0\n",
            "  Downloading pyts-0.12.0-py3-none-any.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 44.2 MB/s \n",
            "\u001b[?25hCollecting rdt<0.7,>=0.6.1\n",
            "  Downloading rdt-0.6.4-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas<2,>=1.1.3 in /usr/local/lib/python3.7/dist-packages (from sdmetrics) (1.1.5)\n",
            "Collecting numpy<2,>=1.20.0\n",
            "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 482 kB/s \n",
            "\u001b[?25hCollecting matplotlib<4,>=3.4.0\n",
            "  Downloading matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 12.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=3.4.0->copulas<0.8,>=0.7.0->sdmetrics) (1.4.4)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.34.4-py3-none-any.whl (944 kB)\n",
            "\u001b[K     |████████████████████████████████| 944 kB 47.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=3.4.0->copulas<0.8,>=0.7.0->sdmetrics) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=3.4.0->copulas<0.8,>=0.7.0->sdmetrics) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=3.4.0->copulas<0.8,>=0.7.0->sdmetrics) (21.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=3.4.0->copulas<0.8,>=0.7.0->sdmetrics) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=3.4.0->copulas<0.8,>=0.7.0->sdmetrics) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib<4,>=3.4.0->copulas<0.8,>=0.7.0->sdmetrics) (4.1.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas<2,>=1.1.3->sdmetrics) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib<4,>=3.4.0->copulas<0.8,>=0.7.0->sdmetrics) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.7/dist-packages (from pyts<0.13.0,>=0.12.0->sdmetrics) (1.1.0)\n",
            "Requirement already satisfied: numba>=0.48.0 in /usr/local/lib/python3.7/dist-packages (from pyts<0.13.0,>=0.12.0->sdmetrics) (0.56.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->pyts<0.13.0,>=0.12.0->sdmetrics) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->pyts<0.13.0,>=0.12.0->sdmetrics) (4.12.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->pyts<0.13.0,>=0.12.0->sdmetrics) (0.39.0)\n",
            "Collecting psutil<6,>=5.7\n",
            "  Downloading psutil-5.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "\u001b[K     |████████████████████████████████| 281 kB 57.5 MB/s \n",
            "\u001b[?25hCollecting pyyaml<6,>=5.4.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 41.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<2,>=0.24->sdmetrics) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.48.0->pyts<0.13.0,>=0.12.0->sdmetrics) (3.8.1)\n",
            "Installing collected packages: numpy, scipy, fonttools, pyyaml, psutil, matplotlib, rdt, pyts, copulas, sdmetrics\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.16.2\n",
            "    Uninstalling numpy-1.16.2:\n",
            "      Successfully uninstalled numpy-1.16.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.2.1\n",
            "    Uninstalling scipy-1.2.1:\n",
            "      Successfully uninstalled scipy-1.2.1\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "Successfully installed copulas-0.7.0 fonttools-4.34.4 matplotlib-3.5.3 numpy-1.21.6 psutil-5.9.1 pyts-0.12.0 pyyaml-5.4.1 rdt-0.6.4 scipy-1.7.3 sdmetrics-0.5.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "psutil",
                  "scipy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sdv\n",
            "  Downloading sdv-0.16.0-py2.py3-none-any.whl (102 kB)\n",
            "\u001b[K     |████████████████████████████████| 102 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas<2,>=1.1.3 in /usr/local/lib/python3.7/dist-packages (from sdv) (1.1.5)\n",
            "Requirement already satisfied: sdmetrics<0.6,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from sdv) (0.5.0)\n",
            "Requirement already satisfied: numpy<2,>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from sdv) (1.21.6)\n",
            "Collecting graphviz<1,>=0.13.2\n",
            "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: rdt<0.7,>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from sdv) (0.6.4)\n",
            "Requirement already satisfied: copulas<0.8,>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from sdv) (0.7.0)\n",
            "Collecting ctgan<0.6,>=0.5.1\n",
            "  Downloading ctgan-0.5.1-py2.py3-none-any.whl (24 kB)\n",
            "Collecting Faker<10,>=3.0.0\n",
            "  Downloading Faker-9.9.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 39.7 MB/s \n",
            "\u001b[?25hCollecting deepecho<0.4,>=0.3.0.post1\n",
            "  Downloading deepecho-0.3.0.post1-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: tqdm<5,>=4.15 in /usr/local/lib/python3.7/dist-packages (from sdv) (4.64.0)\n",
            "Requirement already satisfied: scipy<2,>=1.5.4 in /usr/local/lib/python3.7/dist-packages (from copulas<0.8,>=0.7.0->sdv) (1.7.3)\n",
            "Requirement already satisfied: matplotlib<4,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from copulas<0.8,>=0.7.0->sdv) (3.5.3)\n",
            "Requirement already satisfied: torch<2,>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from ctgan<0.6,>=0.5.1->sdv) (1.12.0+cu113)\n",
            "Requirement already satisfied: torchvision<1,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from ctgan<0.6,>=0.5.1->sdv) (0.13.0+cu113)\n",
            "Requirement already satisfied: packaging<22,>=20 in /usr/local/lib/python3.7/dist-packages (from ctgan<0.6,>=0.5.1->sdv) (21.3)\n",
            "Requirement already satisfied: scikit-learn<2,>=0.24 in /usr/local/lib/python3.7/dist-packages (from ctgan<0.6,>=0.5.1->sdv) (1.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.2 in /usr/local/lib/python3.7/dist-packages (from Faker<10,>=3.0.0->sdv) (4.1.1)\n",
            "Requirement already satisfied: text-unidecode==1.3 in /usr/local/lib/python3.7/dist-packages (from Faker<10,>=3.0.0->sdv) (1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.7/dist-packages (from Faker<10,>=3.0.0->sdv) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=3.4.0->copulas<0.8,>=0.7.0->sdv) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=3.4.0->copulas<0.8,>=0.7.0->sdv) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=3.4.0->copulas<0.8,>=0.7.0->sdv) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=3.4.0->copulas<0.8,>=0.7.0->sdv) (7.1.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=3.4.0->copulas<0.8,>=0.7.0->sdv) (4.34.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas<2,>=1.1.3->sdv) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.4->Faker<10,>=3.0.0->sdv) (1.15.0)\n",
            "Requirement already satisfied: pyyaml<6,>=5.4.1 in /usr/local/lib/python3.7/dist-packages (from rdt<0.7,>=0.6.2->sdv) (5.4.1)\n",
            "Requirement already satisfied: psutil<6,>=5.7 in /usr/local/lib/python3.7/dist-packages (from rdt<0.7,>=0.6.2->sdv) (5.9.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<2,>=0.24->ctgan<0.6,>=0.5.1->sdv) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<2,>=0.24->ctgan<0.6,>=0.5.1->sdv) (3.1.0)\n",
            "Requirement already satisfied: pyts<0.13.0,>=0.12.0 in /usr/local/lib/python3.7/dist-packages (from sdmetrics<0.6,>=0.5.0->sdv) (0.12.0)\n",
            "Requirement already satisfied: numba>=0.48.0 in /usr/local/lib/python3.7/dist-packages (from pyts<0.13.0,>=0.12.0->sdmetrics<0.6,>=0.5.0->sdv) (0.56.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->pyts<0.13.0,>=0.12.0->sdmetrics<0.6,>=0.5.0->sdv) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->pyts<0.13.0,>=0.12.0->sdmetrics<0.6,>=0.5.0->sdv) (4.12.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.48.0->pyts<0.13.0,>=0.12.0->sdmetrics<0.6,>=0.5.0->sdv) (0.39.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision<1,>=0.9.0->ctgan<0.6,>=0.5.1->sdv) (2.23.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.48.0->pyts<0.13.0,>=0.12.0->sdmetrics<0.6,>=0.5.0->sdv) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision<1,>=0.9.0->ctgan<0.6,>=0.5.1->sdv) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision<1,>=0.9.0->ctgan<0.6,>=0.5.1->sdv) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision<1,>=0.9.0->ctgan<0.6,>=0.5.1->sdv) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision<1,>=0.9.0->ctgan<0.6,>=0.5.1->sdv) (1.24.3)\n",
            "Installing collected packages: graphviz, Faker, deepecho, ctgan, sdv\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed Faker-9.9.1 ctgan-0.5.1 deepecho-0.3.0.post1 graphviz-0.20.1 sdv-0.16.0\n"
          ]
        }
      ],
      "source": [
        "!pip install sdmetrics\n",
        "!pip install sdv\n",
        "from pandas._libs.algos import diff_2d\n",
        "import sdmetrics\n",
        "metrics = sdmetrics.multi_table.MultiTableMetric.get_subclasses()\n",
        "from sdv.metrics.tabular import KSTest\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eywrE_Rrmdgu"
      },
      "outputs": [],
      "source": [
        "\n",
        "def getKSTest(H, x_hat):\n",
        "  import sdmetrics\n",
        "  metrics = sdmetrics.multi_table.MultiTableMetric.get_subclasses()\n",
        "  from sdv.metrics.tabular import KSTest\n",
        "  # print('hey')\n",
        "  HDict = {'H': H.flatten()}\n",
        "  df1 = pd.DataFrame(HDict)\n",
        "  private = {'H': x_hat.flatten()}\n",
        "  df2 = pd.DataFrame(private)\n",
        "  raw_score = KSTest.compute(df1.fillna(0), df2.fillna(0))\n",
        "  # print(raw_score)\n",
        "  return raw_score\n",
        "  # val = KSTest.compute(df1, df2)\n",
        "  # return val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWPagSEVkAGA"
      },
      "outputs": [],
      "source": [
        "def getOneDividedByEpsilon(epsilon):\n",
        "  return 1/epsilon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc_LTaDNpogb",
        "outputId": "14eb455e-0164-4764-f4a6-bf0e693d108f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyscagnostics\n",
            "  Downloading pyscagnostics-0.1.0a4-cp37-cp37m-manylinux2010_x86_64.whl (794 kB)\n",
            "\u001b[K     |████████████████████████████████| 794 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.7/dist-packages (from pyscagnostics) (1.21.6)\n",
            "Installing collected packages: pyscagnostics\n",
            "Successfully installed pyscagnostics-0.1.0a4\n"
          ]
        }
      ],
      "source": [
        "!pip install pyscagnostics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXUZyojcp5YB"
      },
      "outputs": [],
      "source": [
        "from pyscagnostics import scagnostics\n",
        "import math\n",
        "def getScagnostics(df, H, xedges, yedges):\n",
        "  x = df['x'].tolist()\n",
        "  y = df['y'].tolist()\n",
        "  newX = []\n",
        "  newY = []\n",
        "  H = H.T\n",
        "  for i in range(len(H)):\n",
        "    for j in range(len(H[i])):\n",
        "      for k in range(int(H[i][j])):\n",
        "        newX.append(np.random.uniform(xedges[i], xedges[i+1]))\n",
        "        newY.append(np.random.uniform(yedges[j], yedges[j+1]))\n",
        "  # plt.plot(newX, newY, 'o', color='black');\n",
        "  measuresOriginal, _ = scagnostics(x, y)\n",
        "  # print(measuresOriginal)\n",
        "  measuresPrivate, _ = scagnostics(newX, newY)\n",
        "  utilityLoss = math.sqrt((abs(measuresOriginal.get('Convex')-measuresPrivate.get('Convex')))**2 \n",
        "  + (abs(measuresOriginal.get('Skinny')-measuresPrivate.get('Skinny')))**2\n",
        "  + (abs(measuresOriginal.get('Stringy')-measuresPrivate.get('Stringy')))**2\n",
        "  + (abs(measuresOriginal.get('Outlying')-measuresPrivate.get('Outlying')))**2\n",
        "  + (abs(measuresOriginal.get('Skewed')-measuresPrivate.get('Skewed')))**2\n",
        "  + (abs(measuresOriginal.get('Clumpy')-measuresPrivate.get('Clumpy')))**2\n",
        "  + (abs(measuresOriginal.get('Sparse')-measuresPrivate.get('Sparse')))**2\n",
        "  + (abs(measuresOriginal.get('Striated')-measuresPrivate.get('Striated')))**2\n",
        "  + (abs(measuresOriginal.get('Monotonic')-measuresPrivate.get('Monotonic')))**2\n",
        "  )\n",
        "\n",
        "  return utilityLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0mQpADJMPyp"
      },
      "outputs": [],
      "source": [
        "!python -m pip uninstall matplotlib\n",
        "!pip install matplotlib==3.1.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lg_vemnH4H-H"
      },
      "outputs": [],
      "source": [
        "l2Df = pd.DataFrame(columns = ['Random Query'])\n",
        "MSSIM =  pd.DataFrame(columns = ['MSSIM'])\n",
        "EarthMovers = pd.DataFrame(columns = ['EarthMovers'])\n",
        "OneDividedByEpsilon = pd.DataFrame(columns = ['OneDividedByEpsilon'])\n",
        "KSTest = pd.DataFrame(columns = ['KSTest'])\n",
        "Scagnostics = pd.DataFrame(columns = ['Scagnostics'])\n",
        "\n",
        "from subprocess import run\n",
        "directory = '/finalData'\n",
        "\n",
        "for filename in os.scandir(directory):\n",
        "    if filename.is_file():\n",
        "        \n",
        "        # df = pd.read_csv(filename.path)\n",
        "        for key, value in chartDictionary.items():\n",
        "          if ('/'+key+'.csv') in (filename.path):\n",
        "            df = pd.read_csv(filename.path)\n",
        "        \n",
        "            for v in value:\n",
        "\n",
        "              for e in epsilons:\n",
        "                for b in bins:\n",
        "                  H, xedges, yedges = np.histogram2d(df['x'], df['y'], bins = b)\n",
        "                  H = H.T\n",
        "                  for a in algorithms:\n",
        "                    if a == 'DAWA':\n",
        "                      dawaPrivate = runDAWA(df, b,e)\n",
        "              \n",
        "                      name = key +'_' + a + '_' + v + '_' + str(e) + '_' + str(b)\n",
        "                      l2Df.loc[name] = [getL2(H, dawaPrivate, b)]\n",
        "                      MSSIM.loc[name] = [getMSSIM(H, dawaPrivate)]\n",
        "                      EarthMovers.loc[name] = [getEarthMoversDistance(H, dawaPrivate)]\n",
        "                      OneDividedByEpsilon.loc[name] = [getOneDividedByEpsilon(e)]\n",
        "                      KSTest.loc[name] = [getKSTest(H, dawaPrivate)]\n",
        "                      Scagnostics.loc[name] = [getScagnostics(df, dawaPrivate, xedges, yedges)]\n",
        "\n",
        "                    \n",
        "\n",
        "\n",
        "                     \n",
        "\n",
        "\n",
        "                    if a == 'AHP':\n",
        "                      ahpPrivate = runAHP(df,b,e)\n",
        "\n",
        "                      name = key +'_' + a + '_' + v + '_' + str(e) + '_' + str(b)\n",
        "                      l2Df.loc[name] = [getL2(H, ahpPrivate, b)]\n",
        "                      MSSIM.loc[name] = [getMSSIM(H, ahpPrivate)]\n",
        "                      EarthMovers.loc[name] = [getEarthMoversDistance(H, ahpPrivate)]\n",
        "                      OneDividedByEpsilon.loc[name] = [getOneDividedByEpsilon(e)]\n",
        "                      KSTest.loc[name] = [getKSTest(H, ahpPrivate)]\n",
        "                      Scagnostics.loc[name] = [getScagnostics(df, ahpPrivate, xedges, yedges)]\n",
        "                     \n",
        "\n",
        "                    if a == \"AGrid\":\n",
        "                      aGridPrivate = runAGrid(df,b,e)\n",
        "          \n",
        "                      name = key +'_' + a + '_' + v + '_' + str(e) + '_' + str(b)\n",
        "                      l2Df.loc[name] = [getL2(H, aGridPrivate, b)]\n",
        "                      MSSIM.loc[name] = [getMSSIM(H, aGridPrivate)]\n",
        "                      EarthMovers.loc[name] = [getEarthMoversDistance(H, aGridPrivate)]\n",
        "                      OneDividedByEpsilon.loc[name] = [getOneDividedByEpsilon(e)]\n",
        "                      KSTest.loc[name] = [getKSTest(H, aGridPrivate)]\n",
        "                      Scagnostics.loc[name] = [getScagnostics(df, aGridPrivate, xedges, yedges)]\n",
        "\n",
        "                    if a == \"Geometric\":\n",
        "                      geoPrivate = runGeoTruncated(df,b,e)\n",
        "                   \n",
        "                      name = key +'_' + a + '_' + v + '_' + str(e) + '_' + str(b)\n",
        "                      l2Df.loc[name] = [getL2(H, geoPrivate, b)]\n",
        "                      MSSIM.loc[name] = [getMSSIM(H, geoPrivate)]\n",
        "                      EarthMovers.loc[name] = [getEarthMoversDistance(H, geoPrivate)]\n",
        "                      OneDividedByEpsilon.loc[name] = [getOneDividedByEpsilon(e)]\n",
        "                      KSTest.loc[name] = [getKSTest(H, geoPrivate)]\n",
        "                      Scagnostics.loc[name] = [getScagnostics(df, geoPrivate, xedges, yedges)]\n",
        "                     \n",
        "                    if a == 'Laplace':\n",
        "                      laplacePrivate = runLaplace(df,b,e)\n",
        "                    \n",
        "                      name = key +'_' + a + '_' + v + '_' + str(e) + '_' + str(b)\n",
        "                      l2Df.loc[name] = [getL2(H, laplacePrivate, b)]\n",
        "                      MSSIM.loc[name] = [getMSSIM(H, laplacePrivate)]\n",
        "                      EarthMovers.loc[name] = [getEarthMoversDistance(H, laplacePrivate)]\n",
        "                      OneDividedByEpsilon.loc[name] = [getOneDividedByEpsilon(e)]\n",
        "                      KSTest.loc[name] = [getKSTest(H, laplacePrivate)]\n",
        "                      Scagnostics.loc[name] = [getScagnostics(df, laplacePrivate, xedges, yedges)]\n",
        "\n",
        "              \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8p4NThQ67dos"
      },
      "outputs": [],
      "source": [
        "l2Series = l2Df.squeeze()\n",
        "MSSIMSeries = MSSIM.squeeze()\n",
        "EarthMoversSeries = EarthMovers.squeeze()\n",
        "OneDividedByEpsilonSeries = OneDividedByEpsilon.squeeze()\n",
        "KSTestSeries = KSTest.squeeze()\n",
        "ScagnosticsSeries = Scagnostics.squeeze()\n",
        "finalDF = pd.concat([l2Series, MSSIMSeries, EarthMoversSeries, OneDividedByEpsilonSeries, KSTestSeries, ScagnosticsSeries], axis=1)\n",
        "\n",
        "finalDF.to_csv('finalUtilityMetrics.csv')  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
